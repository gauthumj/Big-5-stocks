---
title: 'Review 2 Big Five'
output:
  pdf_document: default
  word_document: default
  html_document:
    fig_height: 4
    highlight: pygments
    theme: spacelab
---
### 19BPS1103 Shivaditya Shivganesh

### 19BPS1104 J Gauthum

* * *
## Setup

## Load the Libraries
```{r}
library(keras)
library(tensorflow)
library(dplyr)
library(quantmod)
library(TTR)
```


## Load the Data 
```{r}
data <- read.csv('big_five_stocks.csv')
```


* * *

## Dataset Description

# Name of the Dataset Big Five

# Description of the fields
```{r}
str(data)
```


* * *
Build a time series prediction model using keras and tensorflow
## Transform data to stationary
```{r}
get_ticker_data <- function (data,nam){
  return(filter(data, name == nam))
}

diffedMSFT = diff(get_ticker_data(data,'MSFT')$close,differences = 1)
diffedAAPL = diff(get_ticker_data(data,'AAPL')$close,differences = 1)
diffedAMZN = diff(get_ticker_data(data,'AMZN')$close,differences = 1)
diffedGOOGL = diff(get_ticker_data(data,'GOOGL')$close,differences = 1)
diffedIXIC = diff(get_ticker_data(data,'^IXIC')$close,differences = 1)
```
## Lagged Dataset

```{r}
lag_transform <- function(x, k=1){
  lagged = c(rep(NA, k), x[1:length(x)-k])
  DF = as.data.frame(cbind(lagged,x))
  colnames(DF) <- c(paste0('x-',k),'x')
  DF[is.na(DF)] <- 0
  return (DF)
}

SuperMSFT = lag_transform(diffedMSFT,1)
SuperAAPL = lag_transform(diffedAAPL,1)
SuperAMZN = lag_transform(diffedAMZN,1)
SuperGOOGL = lag_transform(diffedGOOGL,1)
SuperIXIC = lag_transform(diffedIXIC,1)
```




## Amazon (NASDAQ: AMZN)
### Split the data into training and teasting sets

```{r}
N = nrow(SuperAMZN)
n = round(N*0.7,digits = 0)
train = SuperAMZN[1:n, ]
test = SuperAMZN[(n+1):N, ]

```

### Normalize the data

```{r}
scale_data = function(train, test, feature_range = c(0,1)){
  x = train
  fr_min = feature_range[1]
  fr_max = feature_range[2]
  std_train = ((x - min(x)) / (max(x) - min(x)))
  std_test = ((test - min(x)) / (max(x) - min(x) ))
  
  scaled_train = std_train * (fr_max - fr_min) + fr_min
  scaled_test = std_test * (fr_max - fr_min) + fr_min
  
  return (list(scaled_train = as.vector(scaled_train),scaled_test = as.vector(scaled_test),scaler = c(min = max(x), max = max(x))))
  
}

Scaled = scale_data(train,test,c(-1,1))
y_train = Scaled$scaled_train[,2]
x_train = Scaled$scaled_train[,1]

y_test = Scaled$scaled_test[, 2]
x_test = Scaled$scaled_test[, 1]
```

### Invert from Normalized Scale to Orginal Scale

```{r}
inver_scaling = function(scaled, scaler, feature_range = c(0,1)){
  min = scaler[1]
  max = scaler[2]
  t = length(scaled)
  mins = feature_range[1]
  maxs = feature_range[2]
  inverted_dfs = numeric(t)
  
  for (i in 1:t){
    X = (scaled[i] - mins)/(maxs - mins)
    rawValues = X*(max-min) + min
    inverted_dfs[i] <-rawValues
  }
  return(inverted_dfs)
  }

```


### Modeling

#### Define the model
```{r}
dim(x_train) <- c(length(x_train),1 ,1)
#dim(y_train) <- c(length(y_train),1 ,1)

x_shape2 = dim(x_train)[2]
x_shape3 = dim(x_train)[3]
batch_size = 1
units = 1

model <- keras_model_sequential()
model %>%
  layer_lstm(units, batch_input_shape = c(batch_size, x_shape2, x_shape3), stateful = TRUE) %>%
  layer_dense(units = 1)

model %>% compile(
  loss = 'mean_squared_error',
  optimizer = optimizer_adam(learning_rate = 0.02, decay = 1e-6),
  metrics = c("accuracy")
)
summary(model)
```

#### Fit the model

```{r}
Epochs = 50
for(i in 1:Epochs){
  model %>% fit(x_train, y_train, epochs = 1, batch_size = batch_size, verbose = 1, shuffle = FALSE)
  model %>% reset_states()
}
```
#### Make Predictions

```{r}
L = length(x_test)
scaler = Scaled$scaler
predictions = numeric(L)

for (i in 1:L){
  X  = x_test[i]
  dim(X) = c(1,1,1)
  yhat = model %>% predict(X, batch_size = batch_size)
  
  yhat = inver_scaling(yhat, scaler, c(-1,1))
  yhat = yhat + get_ticker_data(data,'AMZN')$close[(n+i)]
  predictions[i] <- yhat
}
```

#### Line plots

```{r}
y_train_p = Scaled$scaled_train[,1]
scaler = Scaled$scaler
L = length(y_train_p)
y_train_p_uns = numeric(L)
for (i in 1:L){
  y_train_p_uns[i] <- train[,1] +  get_ticker_data(data,'AMZN')$close[(n+i)]
}

```

```{r}
plot(get_ticker_data(data,'AMZN')$close,type="line",col="blue")
lines(predictions,type="line",col="red")
```
Charting the Data (Exploring the Data in a Financial Prespective)

#Apple (NASDAQ: AAPL)

Load the data
```{r}
head(get_ticker_data(data,'AAPL'))
getSymbols("AAPL") #Gets Live data from Yahoo Finance
```


```{r}
chartSeries(AAPL, type="line",subset=2007,theme=chartTheme(('white')))
```



## Technical Analysis

### Simple Moving Average
```{r}
chartSeries(AAPL, subset='2007-05::2009-01',theme = chartTheme('white'))
addSMA(n = 30,on =1, col="blue") #30 day period
addSMA(n=200,on=1,col="red") #200 day period
```
### Exponenetial Moving Averages

```{r}
chartSeries(AAPL, subset='2007-05::2009-01',theme = chartTheme('white'))
addEMA(n=30,on=1,col="blue")
addEMA(n=200,on = 1,col="red")
```

### Bollinger Bands

```{r}
chartSeries(AAPL, subset='2007-05::2009-01',theme = chartTheme('white'))
addBBands(n=20,sd=2) #Period 20 with Std dev of 2
```
### Momentum

```{r}
chartSeries(AAPL, subset='2007-05::2009-01',theme = chartTheme('white'))
addMomentum(n=1)
```

### ROC

```{r}
chartSeries(AAPL, subset='2007-05::2009-01',theme = chartTheme('white'))
addROC(n=7)
```

### MACD (Moving Average Convergence Divergence)
```{r}
chartSeries(AAPL, subset='2007-05::2009-01',theme = chartTheme('white'))
addMACD(fast=12,slow=26,signal=9,type="EMA")
```

### RSI (Realtive Strength Index)

```{r}
chartSeries(AAPL, subset='2007-05::2009-01',theme = chartTheme('white'))
addRSI(n=14,maType="EMA")
```


* * *
## Conclusion

Constructed a Simple LSTM based Time-Series forcasting model.
Explained the AAPL Stock Closing prices in Financial Terms

* * *


